#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å— - è½»é‡ç‰ˆ (æ— éœ€numpy)

åŸºäºçŸ¥è¯†å›¾è°±åµŒå…¥æŠ€æœ¯ï¼Œä¸ºçƒ­ç‚¹äº‹ä»¶æä¾›è¯­ä¹‰çº§åˆ«çš„è¡¨ç¤ºå’Œå…³ç³»æ¨ç†

åŠŸèƒ½ï¼š
1. å®ä½“è¡¨ç¤º - å°†äº‹ä»¶ã€ç°è±¡ã€å¿ƒç†ç­‰èŠ‚ç‚¹è¡¨ç¤ºä¸ºå‘é‡
2. å…³ç³»å»ºæ¨¡ - å­¦ä¹ äº‹ä»¶ä¹‹é—´çš„å…³ç³»æ¨¡å¼  
3. è¯­ä¹‰ç›¸ä¼¼åº¦ - è®¡ç®—äº‹ä»¶/ç°è±¡çš„è¯­ä¹‰ç›¸ä¼¼åº¦
4. é“¾æ¥é¢„æµ‹ - é¢„æµ‹äº‹ä»¶ä¹‹é—´å¯èƒ½çš„å…³ç³»
5. å®ä½“èšç±» - è‡ªåŠ¨å‘ç°ç›¸ä¼¼äº‹ä»¶ç¾¤ç»„

ä½œè€…: OpenClaw Agent
åˆ›å»ºæ—¶é—´: 2026-02-09
"""

import os
import json
import math
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class KGEntity:
    """çŸ¥è¯†å›¾è°±å®ä½“"""
    entity_id: str
    name: str
    entity_type: str  # event, phenomenon, psychology, etc.
    attributes: Dict[str, Any] = field(default_factory=dict)
    vector: List[float] = field(default_factory=list)

    def to_vector(self) -> List[float]:
        """è·å–å®ä½“å‘é‡"""
        if self.vector:
            return self.vector
        return self._name_to_vector()

    def _name_to_vector(self) -> List[float]:
        """åŸºäºåç§°ç”Ÿæˆç®€å•å‘é‡"""
        name_bytes = self.name.encode('utf-8')
        vector = [0.0] * 64
        for i, b in enumerate(name_bytes[:64]):
            vector[i] = b / 255.0
        return vector


class SimpleVector:
    """ç®€å•å‘é‡è¿ç®—ï¼ˆæ›¿ä»£numpyï¼‰"""

    @staticmethod
    def dot(v1: List[float], v2: List[float]) -> float:
        return sum(a * b for a, b in zip(v1, v2))

    @staticmethod
    def norm(v: List[float]) -> float:
        return math.sqrt(sum(x * x for x in v))

    @staticmethod
    def cosine(v1: List[float], v2: List[float]) -> float:
        """ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot = SimpleVector.dot(v1, v2)
        norm1 = SimpleVector.norm(v1)
        norm2 = SimpleVector.norm(v2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot / (norm1 * norm2)

    @staticmethod
    def euclidean(v1: List[float], v2: List[float]) -> float:
        """æ¬§æ°è·ç¦»"""
        return math.sqrt(sum((a - b) ** 2 for a, b in zip(v1, v2)))

    @staticmethod
    def add(v1: List[float], v2: List[float]) -> List[float]:
        return [a + b for a, b in zip(v1, v2)]

    @staticmethod
    def sub(v1: List[float], v2: List[float]) -> List[float]:
        return [a - b for a, b in zip(v1, v2)]


class KnowledgeGraphEmbedding:
    """çŸ¥è¯†å›¾è°±åµŒå…¥ç®¡ç†å™¨ï¼ˆè½»é‡ç‰ˆï¼‰"""

    def __init__(self, embedding_dim: int = 64):
        """
        åˆå§‹åŒ–çŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å‹

        å‚æ•°:
            embedding_dim: åµŒå…¥ç»´åº¦
        """
        self.embedding_dim = embedding_dim
        self.entities: Dict[str, KGEntity] = {}
        self.relations: List[Dict] = []
        self.relation_types: set = set()

        logger.info(f"çŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (ç»´åº¦: {embedding_dim})")

    def add_entity(
        self,
        entity_id: str,
        name: str,
        entity_type: str,
        attributes: Optional[Dict] = None
    ) -> KGEntity:
        """æ·»åŠ å®ä½“"""
        entity = KGEntity(
            entity_id=entity_id,
            name=name,
            entity_type=entity_type,
            attributes=attributes or {}
        )
        # ç”Ÿæˆå‘é‡
        entity.vector = self._generate_vector(name, entity_type)
        self.entities[entity_id] = entity
        return entity

    def _generate_vector(self, name: str, entity_type: str) -> List[float]:
        """ç”Ÿæˆå®ä½“å‘é‡"""
        # åç§°å‘é‡
        name_bytes = name.encode('utf-8')
        name_vec = [0.0] * 48
        for i, b in enumerate(name_bytes[:48]):
            name_vec[i] = b / 255.0

        # ç±»å‹å‘é‡ï¼ˆ4ç»´ï¼‰
        type_vec = self._type_to_vector(entity_type)

        # åˆå¹¶
        return name_vec + type_vec

    def _type_to_vector(self, entity_type: str) -> List[float]:
        """å®ä½“ç±»å‹è½¬å‘é‡"""
        type_map = {
            'event': [1.0, 0.0, 0.0, 0.0],
            'phenomenon': [0.0, 1.0, 0.0, 0.0],
            'psychology': [0.0, 0.0, 1.0, 0.0],
            'person': [0.0, 0.0, 0.0, 1.0],
            'organization': [0.5, 0.5, 0.0, 0.0],
            'location': [0.0, 0.0, 0.5, 0.5],
        }
        return type_map.get(entity_type, [0.0] * 4)

    def add_relation(
        self,
        source_entity: str,
        target_entity: str,
        relation_type: str,
        weight: float = 1.0
    ) -> Dict:
        """æ·»åŠ å…³ç³»"""
        relation = {
            'id': f"rel_{len(self.relations)}",
            'source': source_entity,
            'target': target_entity,
            'type': relation_type,
            'weight': weight
        }
        self.relations.append(relation)
        self.relation_types.add(relation_type)
        return relation

    def build_from_events(
        self,
        events: List[Dict],
        phenomena: List[Dict],
        psychologies: List[Dict]
    ) -> bool:
        """ä»çƒ­ç‚¹äº‹ä»¶æ•°æ®æ„å»ºçŸ¥è¯†å›¾è°±åµŒå…¥"""
        logger.info("ä»çƒ­ç‚¹äº‹ä»¶æ„å»ºçŸ¥è¯†å›¾è°±åµŒå…¥...")

        try:
            # æ·»åŠ äº‹ä»¶å®ä½“
            for i, event in enumerate(events):
                self.add_entity(
                    entity_id=f"event_{i}",
                    name=event.get('title', f'Event_{i}'),
                    entity_type='event',
                    attributes=event
                )

            # æ·»åŠ ç°è±¡å®ä½“
            for i, ph in enumerate(phenomena):
                self.add_entity(
                    entity_id=f"phenomenon_{i}",
                    name=ph.get('name', f'Phenomenon_{i}'),
                    entity_type='phenomenon',
                    attributes=ph
                )

            # æ·»åŠ å¿ƒç†å®ä½“
            for i, psy in enumerate(psychologies):
                self.add_entity(
                    entity_id=f"psych_{i}",
                    name=psy.get('name', f'Psychology_{i}'),
                    entity_type='psychology',
                    attributes=psy
                )

            # å»ºç«‹å…³ç³»
            for i in range(len(events)):
                for j in range(len(phenomena)):
                    self.add_relation(
                        f"event_{i}",
                        f"phenomenon_{j}",
                        'leads_to'
                    )

            for j in range(len(phenomena)):
                for k in range(len(psychologies)):
                    self.add_relation(
                        f"phenomenon_{j}",
                        f"psych_{k}",
                        'influences'
                    )

            logger.info(f"  å®ä½“: {len(self.entities)}")
            logger.info(f"  å…³ç³»: {len(self.relations)}")
            logger.info(f"  ç±»å‹: {self.relation_types}")

            return True

        except Exception as e:
            logger.error(f"æ„å»ºå¤±è´¥: {e}")
            return False

    def get_similarity(
        self,
        entity_id_1: str,
        entity_id_2: str,
        method: str = 'cosine'
    ) -> float:
        """è®¡ç®—ä¸¤ä¸ªå®ä½“çš„ç›¸ä¼¼åº¦"""
        if entity_id_1 not in self.entities or entity_id_2 not in self.entities:
            return 0.0

        vec1 = self.entities[entity_id_1].to_vector()
        vec2 = self.entities[entity_id_2].to_vector()

        if method == 'cosine':
            return SimpleVector.cosine(vec1, vec2)
        elif method == 'euclidean':
            dist = SimpleVector.euclidean(vec1, vec2)
            return 1.0 / (1.0 + dist)
        else:
            return SimpleVector.cosine(vec1, vec2)

    def find_similar_entities(
        self,
        entity_id: str,
        top_k: int = 5,
        entity_type: Optional[str] = None
    ) -> List[Tuple[str, str, float]]:
        """æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å®ä½“"""
        if entity_id not in self.entities:
            return []

        target_vec = self.entities[entity_id].to_vector()
        similarities = []

        for other_id, entity in self.entities.items():
            if other_id == entity_id:
                continue

            if entity_type and entity.entity_type != entity_type:
                continue

            sim = SimpleVector.cosine(target_vec, entity.to_vector())
            similarities.append((other_id, entity.name, sim))

        similarities.sort(key=lambda x: x[2], reverse=True)
        return similarities[:top_k]

    def predict_links(
        self,
        source_entity_id: str,
        candidate_ids: List[str],
        top_k: int = 3
    ) -> List[Tuple[str, str, float]]:
        """é¢„æµ‹å¯èƒ½çš„å…³ç³»ç›®æ ‡"""
        if source_entity_id not in self.entities:
            return []

        source_vec = self.entities[source_entity_id].to_vector()
        predictions = []

        for entity_id in candidate_ids:
            if entity_id not in self.entities:
                continue

            sim = SimpleVector.cosine(source_vec, self.entities[entity_id].to_vector())
            predictions.append((entity_id, self.entities[entity_id].name, sim))

        predictions.sort(key=lambda x: x[2], reverse=True)
        return predictions[:top_k]

    def find_clusters(
        self,
        entity_type: str,
        n_clusters: int = 3
    ) -> Dict[int, List[str]]:
        """å¯¹å®ä½“è¿›è¡Œèšç±»ï¼ˆç®€åŒ–ç‰ˆK-Meansï¼‰"""
        # æ”¶é›†å®ä½“
        entity_list = [
            (eid, ent) for eid, ent in self.entities.items()
            if ent.entity_type == entity_type
        ]

        if len(entity_list) < n_clusters:
            return {}

        # åˆå§‹åŒ–èšç±»ä¸­å¿ƒ
        centers = {}
        for i in range(n_clusters):
            _, entity = entity_list[i % len(entity_list)]
            centers[i] = entity.to_vector().copy()

        # è¿­ä»£èšç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰
        max_iter = 10
        for _ in range(max_iter):
            clusters = defaultdict(list)

            for eid, entity in entity_list:
                vec = entity.to_vector()
                best_cluster = 0
                best_sim = -1

                for cid, center in centers.items():
                    sim = SimpleVector.cosine(vec, center)
                    if sim > best_sim:
                        best_sim = sim
                        best_cluster = cid

                clusters[best_cluster].append(eid)

            # æ›´æ–°èšç±»ä¸­å¿ƒ
            for cid in centers:
                if cid in clusters and clusters[cid]:
                    cluster_entities = [self.entities[eid] for eid in clusters[cid]]
                    # è®¡ç®—æ‰€æœ‰å‘é‡çš„å¹³å‡å€¼
                    all_vectors = [ent.to_vector() for ent in cluster_entities]
                    avg_vector = []
                    for i in range(self.embedding_dim):
                        avg_value = sum(v[i] if i < len(v) else 0 for v in all_vectors) / len(all_vectors)
                        avg_vector.append(avg_value)
                    centers[cid] = avg_vector

        return dict(clusters)

    def export_data(self) -> Dict:
        """å¯¼å‡ºæ‰€æœ‰æ•°æ®"""
        return {
            'entities': {
                eid: {
                    'name': ent.name,
                    'type': ent.entity_type,
                    'vector': ent.vector,
                    'attributes': ent.attributes
                }
                for eid, ent in self.entities.items()
            },
            'relations': self.relations,
            'statistics': self.get_statistics()
        }

    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        type_counts = defaultdict(int)
        for ent in self.entities.values():
            type_counts[ent.entity_type] += 1

        return {
            'total_entities': len(self.entities),
            'total_relations': len(self.relations),
            'entity_types': dict(type_counts),
            'relation_types': list(self.relation_types),
            'embedding_dim': self.embedding_dim
        }


def demo():
    """æ¼”ç¤º"""
    print("=" * 70)
    print("çŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å—æ¼”ç¤º")
    print("=" * 70)

    # åˆ›å»ºåµŒå…¥æ¨¡å‹
    embedder = KnowledgeGraphEmbedding(embedding_dim=64)

    # æ·»åŠ ç¤ºä¾‹å®ä½“
    events = [
        ('e1', 'AIå¤§æ¨¡å‹çªç ´', 'event'),
        ('e2', 'æ–°èƒ½æºæ±½è½¦é”€é‡å¢é•¿', 'event'),
        ('e3', 'æˆ¿åœ°äº§å¸‚åœºè°ƒæ•´', 'event'),
        ('e4', 'äº’è”ç½‘å¹³å°ç›‘ç®¡åŠ å¼º', 'event'),
        ('e5', '5Gç½‘ç»œå•†ç”¨åŠ é€Ÿ', 'event'),
        ('p1', 'æŠ€æœ¯æ™®åŠ', 'phenomenon'),
        ('p2', 'èµ„æœ¬æŠ•å…¥', 'phenomenon'),
        ('p3', 'æ”¿ç­–è§„èŒƒ', 'phenomenon'),
        ('m1', 'ç§¯æä¹è§‚', 'psychology'),
        ('m2', 'ç„¦è™‘æ‹…å¿§', 'psychology'),
        ('m3', 'æœŸå¾…å…´å¥‹', 'psychology'),
    ]

    for eid, name, etype in events:
        embedder.add_entity(eid, name, etype)

    # å»ºç«‹å…³ç³»
    relations = [
        ('e1', 'p1', 'leads_to'),
        ('e2', 'p1', 'leads_to'),
        ('e2', 'p2', 'leads_to'),
        ('e3', 'p2', 'leads_to'),
        ('e4', 'p3', 'leads_to'),
        ('e5', 'p1', 'leads_to'),
        ('p1', 'm1', 'influences'),
        ('p1', 'm3', 'influences'),
        ('p2', 'm2', 'influences'),
        ('p3', 'm2', 'influences'),
    ]

    for src, tgt, rel in relations:
        embedder.add_relation(src, tgt, rel)

    # æ˜¾ç¤ºç»Ÿè®¡
    stats = embedder.get_statistics()
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å®ä½“æ•°: {stats['total_entities']}")
    print(f"   å…³ç³»æ•°: {stats['total_relations']}")
    print(f"   å®ä½“ç±»å‹: {stats['entity_types']}")
    print(f"   å…³ç³»ç±»å‹: {stats['relation_types']}")

    # è®¡ç®—ç›¸ä¼¼åº¦
    print(f"\nğŸ” äº‹ä»¶ç›¸ä¼¼åº¦:")
    pairs = [('e1', 'e2'), ('e1', 'e5'), ('e2', 'e3')]
    for e1, e2 in pairs:
        sim = embedder.get_similarity(e1, e2)
        print(f"   {embedder.entities[e1].name} vs {embedder.entities[e2].name}: {sim:.4f}")

    # æŸ¥æ‰¾ç›¸ä¼¼å®ä½“
    print(f"\nğŸ¯ ä¸'AIå¤§æ¨¡å‹çªç ´'æœ€ç›¸ä¼¼çš„äº‹ä»¶:")
    similar = embedder.find_similar_entities('e1', top_k=3, entity_type='event')
    for sid, name, score in similar:
        print(f"   - {name}: {score:.4f}")

    # é“¾æ¥é¢„æµ‹
    print(f"\nğŸ”— é¢„æµ‹ä¸'æˆ¿åœ°äº§å¸‚åœºè°ƒæ•´'å¯èƒ½ç›¸å…³çš„äº‹ä»¶:")
    candidates = [eid for eid in embedder.entities if eid.startswith('e') and eid != 'e3']
    predictions = embedder.predict_links('e3', candidates, top_k=3)
    for pid, name, score in predictions:
        print(f"   - {name}: {score:.4f}")

    # èšç±»
    print(f"\nğŸ“‚ äº‹ä»¶èšç±»ç»“æœ (2ç±»):")
    clusters = embedder.find_clusters('event', n_clusters=2)
    for cid, eids in clusters.items():
        names = [embedder.entities[eid].name for eid in eids]
        print(f"   èšç±»{cid}: {names}")

    # ç°è±¡å…³è”
    print(f"\nğŸ”— ç°è±¡ä¹‹é—´çš„å…³ç³»:")
    phenomenon_ids = [eid for eid in embedder.entities if eid.startswith('p')]
    for i, pid1 in enumerate(phenomenon_ids):
        for pid2 in phenomenon_ids[i+1:]:
            sim = embedder.get_similarity(pid1, pid2)
            print(f"   {embedder.entities[pid1].name} <-> {embedder.entities[pid2].name}: {sim:.4f}")

    print("\n" + "=" * 70)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    demo()
